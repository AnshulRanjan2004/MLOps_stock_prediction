name: data upload to azure
on:
  push:
    branches:
      - "data-upload-automation"
  schedule:
    - cron: '*/2 * * * *'
jobs:
  uploaddata:
    runs-on: ubuntu-latest
    steps:
    - name: checkout repository
      uses: actions/checkout@v2
    - name: setup python 3.9
      uses: actions/setup-python@v4
      with: 
        python-version: "3.9"
    - name: install python packages
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: azure login
      uses: azure/login@v1
      with:
        creds: ${{secrets.AZURE_CREDENTIALS}}
    - name: setup
      run: bash setup.sh
      working-directory: cli
      continue-on-error: true
    - name: download the data
      run: python download_ticker_data.py
      id: data
      working-directory: jobs
    - name: write out csv
      uses: gr2m/write-csv-file-action@v1.x
      with:
          path: data/{{ steps.data.output.filename }}.csv
          columns: Date, Close
          "Date": $ {{ steps.data.outputs.Date }}
          "Close": $ {{ steps.data.outputs.Close }}
    - run: git config --local user.email "action@github.com"
    - run: git config --local user.name "GitHub Action"
    - run: git add data
    - run: git commit -m "data/{{steps.data.outputs.file_name}}.csv updated"
    - run: "git push https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git HEAD"
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    # - name: upload to azure
    #   run: az ml data create -f jobs/data.yml

# # #
# 1. Ensure Azure login job is working
# 2. Ensure downloaded file is saved
# 3. Check if the file is saved in the yaml file using if clause
# 4. Write out file params in a json or something
# 5. If the file is saved, upload the file to Azure after reading the file params
# 6. 
# 7. 
# 8.
# # #