{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK v1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.core.compute import AmlCompute,ComputeTarget, ComputeInstance\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.environment import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path='../../config/config.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=Environment.from_pip_requirements(\"conv_sum\",  '../config/requirements.txt')\n",
    "env.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ComputeManagement import create_cluster, create_instance, delete_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=create_cluster(\n",
    "    workspaceRef=ws,\n",
    "    name=\"q34\",\n",
    "    vmSize=\"Standard_DS3_v2\",\n",
    "    minNodes=0,\n",
    "    maxNodes=4,\n",
    "    idleTime=180\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_script_config = ScriptRunConfig(\n",
    "#     source_directory = 'src',\n",
    "#     script = 'training_script.py',\n",
    "#     arguments=['--data',___],\n",
    "#     environment = env,\n",
    "#     compute_target = cc\n",
    "# )\n",
    "# experiment = Experiment(\n",
    "#     workspace = ws,\n",
    "#     name=\"maiden_experiment\"\n",
    "# )\n",
    "# run = experiment.submit(config=training_script_config, tags=[])\n",
    "\n",
    "# RunDetails(run).show()\n",
    "# run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensexTickerYFinance = ['HDFCLIFE.NS, NESTLEIND.NS, KOTAKBANK.NS, INDUSINDBK.NS, TATASTEEL.NS, ITC.NS, ONGC.NS, TITAN.NS, ULTRACEMCO.NS, BAJAJFINSV.NS, BAJFINANCE.NS, BRITANNIA.NS, BAJAJ-AUTO.NS, COALINDIA.NS, BHARTIARTL.NS, TATACONSUM.NS, LTI.NS, CIPLA.NS, MARUTI.NS, ICICIBANK.NS, APOLLOHOSP.NS, NTPC.NS, HEROMOTOCO.NS, HINDALCO.NS, WIPRO.NS, TCS.NS, ADANIENT.NS, MM.NS, TECHM.NS, RELIANCE.NS']\n",
    "stock_data = yf.download(tickers=sensexTickerYFinance, start='2000-01-01', end='2022-12-31', interval='1mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.loc[:,'Adj Close']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO\n",
    "1. Read about SOTA for stock price prediction and what determines success of model trying to predict price\n",
    "2. Choose stocks to monitor - Nifty 50\n",
    "3. Build as below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of a common use-case where data would update regularly and model would shift\n",
    "1. Stock price prediction\n",
    "2. Automatic data retrieval using API to store into Azure storage\n",
    "3. Automatic model training at intervals depending on error rate\n",
    "\n",
    "Tie everything up in a RL portfolio optimization application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerData= yf.download(tickers=\"RELIANCE.NS\", start=\"2022-01-01\", end=\"2023-01-10\", period=\"1d\")\n",
    "tickerData['Date'] = [str(x)[:10] for x in tickerData.index]\n",
    "tickerData['Ticker'] = \"RELIANCE.NS\"\n",
    "tickerDataToPersist = list(tickerData.transpose().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.TickerData import query, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(ticker=\"RELIANCE.NS\", start=\"2022-12-01\",end=\"2023-01-10\", period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = query(ticker=\"RELIANCE.NS\", start=\"2022-12-01\",end=\"2023-01-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker=\"RELIANCE.NS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[f\"{ticker}_Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_data).to_csv('./data/ril.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(series, loookaheadSize=5):\n",
    "    X,y = [],[]\n",
    "    for i in np.arange(5,len(series)-1):\n",
    "        X.append(series[i-loookaheadSize:i])\n",
    "        y.append(series[i+1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(len(series)-loookaheadSize-1,1,5)\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=training_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tx,'txx.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = torch.load('txx.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(typ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0.0026]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "str(datetime.now().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK v2 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from azure.ai.ml import MLClient, Input, Output, command\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import AmlCompute, Environment, Model, Data, CodeConfiguration, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.json','r') as f:\n",
    "    configs=json.loads(f.read())\n",
    "\n",
    "subscription_id, resource_group, workspace = configs['subscription_id'], configs['resource_group'], configs['workspace_name']\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential, subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_cluster(\n",
    "    TargetName = \"cpu-cluster\",\n",
    "    computeSize=\"STANDARD_DS3_V2\",\n",
    "    minInstances=1,\n",
    "    maxInstances=4,\n",
    "    idleTime=180,\n",
    "    ):\n",
    "\n",
    "    try:\n",
    "        compute = ml_client.compute.get(TargetName)\n",
    "    except Exception:\n",
    "        print(\"Creating a new cpu compute target...\")\n",
    "        # Let's create the Azure ML compute object with the intended parameters\n",
    "        compute = AmlCompute(\n",
    "            name=TargetName,\n",
    "            type=\"amlcompute\",\n",
    "            size=computeSize,\n",
    "            min_instances=minInstances,\n",
    "            max_instances=maxInstances,\n",
    "            idle_time_before_scale_down=idleTime,\n",
    "        )\n",
    "        # Now, we pass the object to MLClient's create_or_update method\n",
    "        compute = ml_client.begin_create_or_update(compute)    \n",
    "    return compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new cpu compute target...\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "compute = create_train_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x15360f410>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......."
     ]
    }
   ],
   "source": [
    "compute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies_dir = \"../config\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../config/conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - yfinance==0.2.4\n",
    "    - pymongo==4.3.3\n",
    "    - torch==1.13.1\n",
    "    - scikit-learn==1.2.0\n",
    "    - werkzeug==0.16.1\n",
    "    - opencensus==0.11.1\n",
    "    - markupsafe==2.0.1\n",
    "    - opencensus-ext-azure==1.1.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_env(\n",
    "    dependencies_dir,\n",
    "    envName = \"stock-pred\"\n",
    "    ):\n",
    "\n",
    "    env = Environment(\n",
    "        name=envName,\n",
    "        description=\"Custom environment for creating MLOps project for stock prediction\",\n",
    "        conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "        version=\"0.1.6\",\n",
    "    )\n",
    "    env = ml_client.environments.create_or_update(env)\n",
    "\n",
    "    print(\n",
    "        f\"Environment with name {env.name} is registered to workspace, the environment version is {env.version}\"\n",
    "    )\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Environment with name stock-pred is registered to workspace, the environment version is 0.1.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    }
   ],
   "source": [
    "env = register_env(dependencies_dir=dependencies_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'ril', 'description': 'ril_stock_data', 'tags': {}, 'properties': {}, 'id': '/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/providers/Microsoft.MachineLearningServices/workspaces/AzureMLWorkspace/data/ril/versions/1', 'Resource__source_path': None, 'base_path': '/Users/anupam/Documents/Codebase/MLOps_stock_prediction/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x10ce04b10>, 'serialize': <msrest.serialization.Serializer object at 0x10ce06410>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourcegroups/RG/workspaces/AzureMLWorkspace/datastores/workspaceblobstore/paths/LocalUpload/3e91b5da3fd7435efb8a68549a7c027a/ril.csv', 'datastore': None})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path = '../data/ril.csv'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"ril_stock_data\",\n",
    "    name=\"ril\",\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ril_data = ml_client.data.get(name='ril', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml://subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourcegroups/RG/workspaces/AzureMLWorkspace/datastores/workspaceblobstore/paths/LocalUpload/3e91b5da3fd7435efb8a68549a7c027a/ril.csv'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ril_data.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"../src/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src//Train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {src_dir}/Train.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def series_to_tensors(series, lookaheadSize=5):\n",
    "\n",
    "    X,y = [],[]\n",
    "    for i in np.arange(5,len(series)-1):\n",
    "        X.append(series[i-lookaheadSize:i])\n",
    "        y.append(series[i+1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(len(series)-lookaheadSize-1,1,5)\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def dataprep(args):\n",
    "\n",
    "    stockData = pd.read_csv(args.data, index_col='Unnamed: 0')\n",
    "    stock_train_df, stock_test_df = train_test_split(stockData, test_size=args.test_train_ratio)\n",
    "\n",
    "    print(stock_train_df)\n",
    "\n",
    "    # Instead of this use LayerNorm or BatchNorm in the neural net\n",
    "    scaler = MinMaxScaler().fit(stock_train_df)\n",
    "    stock_train_df = scaler.transform(stock_train_df)\n",
    "    stock_test_df = scaler.transform(stock_test_df)\n",
    "\n",
    "    train_tensors = series_to_tensors(stock_train_df)\n",
    "    test_tensors = series_to_tensors(stock_test_df)\n",
    "\n",
    "    return scaler, train_tensors, test_tensors\n",
    "\n",
    "class lstm_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(lstm_model, self).__init__()\n",
    "        self.lstm1=torch.nn.LSTM(batch_first=True, input_size=5, hidden_size=1)\n",
    "        self.out=torch.nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm1(x)\n",
    "        x = self.out(x)\n",
    "        return x.flatten()\n",
    "\n",
    "def train(trainset):\n",
    "\n",
    "    seq_model = lstm_model()\n",
    "    optim = torch.optim.Adam(lr = 0.0001, params=seq_model.parameters())\n",
    "\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in np.arange(epochs):\n",
    "\n",
    "        Loss=0\n",
    "\n",
    "        for data in trainset:\n",
    "\n",
    "            feats, target = data\n",
    "            optim.zero_grad()\n",
    "\n",
    "            y_p = seq_model(feats.float())\n",
    "            loss = torch.nn.functional.mse_loss(y_p.float(), target.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            Loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch}, loss: {Loss}\")\n",
    "    return seq_model\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    parser.add_argument(\"--data\", type=str, help=\"Path to input data\")\n",
    "    parser.add_argument(\"--local_model_name\", type=str, required=True, default=0.25)\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Load Scaler object later and send it for scaling data\n",
    "\n",
    "    scaler, trainset, _ = dataprep(args)\n",
    "\n",
    "    trainedModel = train(trainset)\n",
    "\n",
    "    print(os.getcwd())\n",
    "\n",
    "    pickle.dump(scaler, open('./outputs/scaler.pkl','wb'))\n",
    "    model_file = f\"./outputs/{args.local_model_name}.pth\"\n",
    "    torch.save(trainedModel, model_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def version_iter(n=20):\n",
    "    i=0\n",
    "    for i in np.arange(21,50):\n",
    "        yield i\n",
    "x = iter(version_iter())\n",
    "next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'stock-pred' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'stock-pred' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.01 MBs): 100%|██████████| 11081/11081 [00:01<00:00, 9129.91it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>train_model_stock_price_prediction</td><td>stock_pred_job_32</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/stock_pred_job_32?wsid=/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourcegroups/RG/workspaces/AzureMLWorkspace&amp;tid=d390d3b6-5b59-47f2-a790-59a4e06413d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Starting', 'log_files': None, 'name': 'stock_pred_job_32', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/coderkol95/MLOps_stock_prediction.git', 'mlflow.source.git.branch': 'AzureML_SDK_v2', 'mlflow.source.git.commit': '434e64e61749281e2281b97f8883b867730d0b51', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'c62c62ff-aa62-452f-9a7f-23d147350c1f'}, 'id': '/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/providers/Microsoft.MachineLearningServices/workspaces/AzureMLWorkspace/jobs/stock_pred_job_32', 'Resource__source_path': None, 'base_path': '/Users/anupam/Documents/Codebase/MLOps_stock_prediction/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x153b00650>, 'serialize': <msrest.serialization.Serializer object at 0x153b27150>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'stock_price_prediction', 'experiment_name': 'train_model_stock_price_prediction', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x152faa190>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x153b1e850>}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourcegroups/RG/workspaces/AzureMLWorkspace/datastores/workspaceblobstore/paths/LocalUpload/3e91b5da3fd7435efb8a68549a7c027a/ril.csv', 'mode': 'ro_mount'}, 'test_train_ratio': '0.25', 'registered_model_name': 'stock_pred_v1', 'local_model_name': 'modelstock_pred_2023-01-23'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.stock_pred_job_32', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x153b26250>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x153b261d0>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x153b25e90>, 'local_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x153b26cd0>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x153b275d0>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'stock_pred_job_32', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x153b00650>, 'serialize': <msrest.serialization.Serializer object at 0x153b27810>, 'command': 'python Train.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --local_model_name ${{inputs.local_model_name}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/providers/Microsoft.MachineLearningServices/workspaces/AzureMLWorkspace/codes/d95329a3-39a1-459a-9077-6ebf2e90e042/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/providers/Microsoft.MachineLearningServices/workspaces/AzureMLWorkspace/environments/stock-pred/versions/0.1.4', 'distribution': None, 'resources': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'stock_price_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourcegroups/RG/workspaces/AzureMLWorkspace/datastores/workspaceblobstore/paths/LocalUpload/3e91b5da3fd7435efb8a68549a7c027a/ril.csv', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.25'}, 'registered_model_name': {'type': 'string', 'default': 'stock_pred_v1'}, 'local_model_name': {'type': 'string', 'default': 'modelstock_pred_2023-01-23'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.stock_pred_job_32', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x152faa190>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x153b1e850>}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x153b00650>}, 'instance_id': 'f00274e7-7d20-448a-b2d5-324ca368e108', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'stock-pred:0.1.4', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'swept': False})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_name = f\"modelstock_pred_{str(datetime.now().date())}\"\n",
    "registered_model_name = \"stock_pred_v1\"\n",
    "\n",
    "job = command(   \n",
    "    name=f\"stock_pred_job_{next(x)}\",\n",
    "    inputs={\n",
    "        \"data\": Input(type=AssetTypes.URI_FILE, mode=\"ro_mount\", path=ril_data.path),\n",
    "        \"test_train_ratio\": 0.25,\n",
    "        \"registered_model_name\":registered_model_name,\n",
    "        \"local_model_name\":local_model_name\n",
    "        },\n",
    "    code=\"../src/\",  # location of source code\n",
    "    command=\"python Train.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --local_model_name ${{inputs.local_model_name}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
    "    environment=env,\n",
    "    compute=compute.name,\n",
    "    experiment_name=\"train_model_stock_price_prediction\",\n",
    "    display_name=\"stock_price_prediction\",\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_name=f\"modelstock_pred_{str(datetime.now().date())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelstock_pred_2023-01-23'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "        path=f\"azureml://jobs/{job.name}/outputs/artifacts/paths/outputs/{local_model_name}.pth\",\n",
    "        name=\"run-model-example\",\n",
    "        description=\"Model created from run.\",\n",
    "        type=\"custom_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model({'job_name': 'stock_pred_job_32', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'run-model-example', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/providers/Microsoft.MachineLearningServices/workspaces/AzureMLWorkspace/models/run-model-example/versions/2', 'Resource__source_path': None, 'base_path': '/Users/anupam/Documents/Codebase/MLOps_stock_prediction/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x1539376d0>, 'serialize': <msrest.serialization.Serializer object at 0x153ea3fd0>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/5d2e45e0-cd7b-4338-b279-455fa4a4c42d/resourceGroups/RG/workspaces/AzureMLWorkspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.stock_pred_job_32/outputs/modelstock_pred_2023-01-23.pth', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.models.create_or_update(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src//Deployment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {src_dir}/Deployment.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "\n",
    "class lstm_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(lstm_model, self).__init__()\n",
    "        self.lstm1=torch.nn.LSTM(batch_first=True, input_size=5, hidden_size=1)\n",
    "        self.out=torch.nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm1(x)\n",
    "        x = self.out(x)\n",
    "        return x.flatten()\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model\n",
    "    global scaler\n",
    "\n",
    "    scalerpath = os.path.join(\n",
    "    os.getenv(\"AZUREML_MODEL_DIR\"), \"outputs/scaler.pkl\")\n",
    "    print(scalerpath)\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    with open(scalerpath, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    modelpath = os.path.join(\n",
    "    os.getenv(\"AZUREML_MODEL_DIR\"), \"outputs/modelstock_pred_2023-01-23.pth\")    \n",
    "    print(modelpath)\n",
    "    model = lstm_model()\n",
    "    model = torch.load(modelpath)\n",
    "\n",
    "def run(raw_data):\n",
    "\n",
    "    data = json.loads(raw_data)[\"data\"]\n",
    "    data = np.array(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "\n",
    "    result = model.predict(scaled_data)\n",
    "\n",
    "    return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x140f0c650>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model\n",
    "modeldir = ml_client.models.get(name=\"run-model-example\", version=\"1\")\n",
    "# model = ml_client.models.get(name=\"run-model-example\", version=\"2\")\n",
    "\n",
    "# Create endpoint\n",
    "online_endpoint_name = \"modeldir-logged-init-3\"\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\"\n",
    ")\n",
    "\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create deployment only after endpoint has provisioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint modeldir-logged-init-3 exists\n",
      "Uploading src (0.01 MBs): 100%|██████████| 12214/12214 [00:01<00:00, 7945.28it/s]\n",
      "\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x154869bd0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................."
     ]
    }
   ],
   "source": [
    "# Deployment script\n",
    "code_config = CodeConfiguration(\n",
    "        code=src_dir, scoring_script=\"Deployment.py\"\n",
    "    )\n",
    "\n",
    "# Create deployment\n",
    "yellow_deployment = ManagedOnlineDeployment(\n",
    "    name=\"yellow\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=modeldir,\n",
    "    environment=Environment(\n",
    "            conda_file=f\"./{dependencies_dir}/conda.yml\",\n",
    "            image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\"),\n",
    "    code_configuration=code_config,\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "# create the deployment:\n",
    "ml_client.begin_create_or_update(yellow_deployment)\n",
    "# blue deployment takes 100 traffic\n",
    "# endpoint.traffic = {\"yellow\": 100}\n",
    "# ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are no logs for this deployment at the moment. Please try again later.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"yellow\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the endpoint (the request will route to blue deployment as set above)\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"../model-1/sample-request.json\",\n",
    ")\n",
    "\n",
    "# test the specific (blue) deployment\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"yellow\",\n",
    "    request_file=\"../model-1/sample-request.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495794734634ed83a223a0ff466dd16659bfe4b87c179f1ac740ad96b06e37ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
