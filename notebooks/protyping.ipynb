{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK v1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.core.compute import AmlCompute,ComputeTarget, ComputeInstance\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.environment import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path='../../config/config.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=Environment.from_pip_requirements(\"conv_sum\",  '../config/requirements.txt')\n",
    "env.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ComputeManagement import create_cluster, create_instance, delete_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=create_cluster(\n",
    "    workspaceRef=ws,\n",
    "    name=\"q34\",\n",
    "    vmSize=\"Standard_DS3_v2\",\n",
    "    minNodes=0,\n",
    "    maxNodes=4,\n",
    "    idleTime=180\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_script_config = ScriptRunConfig(\n",
    "#     source_directory = 'src',\n",
    "#     script = 'training_script.py',\n",
    "#     arguments=['--data',___],\n",
    "#     environment = env,\n",
    "#     compute_target = cc\n",
    "# )\n",
    "# experiment = Experiment(\n",
    "#     workspace = ws,\n",
    "#     name=\"maiden_experiment\"\n",
    "# )\n",
    "# run = experiment.submit(config=training_script_config, tags=[])\n",
    "\n",
    "# RunDetails(run).show()\n",
    "# run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensexTickerYFinance = ['HDFCLIFE.NS, NESTLEIND.NS, KOTAKBANK.NS, INDUSINDBK.NS, TATASTEEL.NS, ITC.NS, ONGC.NS, TITAN.NS, ULTRACEMCO.NS, BAJAJFINSV.NS, BAJFINANCE.NS, BRITANNIA.NS, BAJAJ-AUTO.NS, COALINDIA.NS, BHARTIARTL.NS, TATACONSUM.NS, LTI.NS, CIPLA.NS, MARUTI.NS, ICICIBANK.NS, APOLLOHOSP.NS, NTPC.NS, HEROMOTOCO.NS, HINDALCO.NS, WIPRO.NS, TCS.NS, ADANIENT.NS, MM.NS, TECHM.NS, RELIANCE.NS']\n",
    "stock_data = yf.download(tickers=sensexTickerYFinance, start='2000-01-01', end='2022-12-31', interval='1mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.loc[:,'Adj Close']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO\n",
    "1. Read about SOTA for stock price prediction and what determines success of model trying to predict price\n",
    "2. Choose stocks to monitor - Nifty 50\n",
    "3. Build as below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of a common use-case where data would update regularly and model would shift\n",
    "1. Stock price prediction\n",
    "2. Automatic data retrieval using API to store into Azure storage\n",
    "3. Automatic model training at intervals depending on error rate\n",
    "\n",
    "Tie everything up in a RL portfolio optimization application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerData= yf.download(tickers=\"RELIANCE.NS\", start=\"2022-01-01\", end=\"2023-01-10\", period=\"1d\")\n",
    "tickerData['Date'] = [str(x)[:10] for x in tickerData.index]\n",
    "tickerData['Ticker'] = \"RELIANCE.NS\"\n",
    "tickerDataToPersist = list(tickerData.transpose().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.TickerData import query, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(ticker=\"RELIANCE.NS\", start=\"2022-12-01\",end=\"2023-01-10\", period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = query(ticker=\"RELIANCE.NS\", start=\"2022-12-01\",end=\"2023-01-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker=\"RELIANCE.NS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[f\"{ticker}_Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_data).to_csv('./data/ril.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(series, loookaheadSize=5):\n",
    "    X,y = [],[]\n",
    "    for i in np.arange(5,len(series)-1):\n",
    "        X.append(series[i-loookaheadSize:i])\n",
    "        y.append(series[i+1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(len(series)-loookaheadSize-1,1,5)\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=training_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tx,'txx.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = torch.load('txx.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(typ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0.0026]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "str(datetime.now().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK v2 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from azure.ai.ml import MLClient, Input, Output, command\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import AmlCompute, Environment, Model, Data, CodeConfiguration, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.json','r') as f:\n",
    "    configs=json.loads(f.read())\n",
    "\n",
    "subscription_id, resource_group, workspace = configs['subscription_id'], configs['resource_group'], configs['workspace_name']\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential, subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '../data/ril.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ril_data = ml_client.data.get(name='ril', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ril_data.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_iter(n=20):\n",
    "    i=0\n",
    "    for i in np.arange(21,50):\n",
    "        yield i\n",
    "x = iter(version_iter())\n",
    "next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_name = f\"modelstock_pred_{str(datetime.now().date())}\"\n",
    "registered_model_name = \"stock_pred_v1\"\n",
    "\n",
    "job = command(   \n",
    "    name=f\"stock_pred_job_{next(x)}\",\n",
    "    inputs={\n",
    "        \"data\": Input(type=AssetTypes.URI_FILE, mode=\"ro_mount\", path=ril_data.path),\n",
    "        \"test_train_ratio\": 0.25,\n",
    "        \"registered_model_name\":registered_model_name,\n",
    "        \"local_model_name\":local_model_name\n",
    "        },\n",
    "    code=\"../src/\",  # location of source code\n",
    "    command=\"python train.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --local_model_name ${{inputs.local_model_name}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
    "    environment=env,\n",
    "    compute=compute.name,\n",
    "    experiment_name=\"train_model_stock_price_prediction\",\n",
    "    display_name=\"stock_price_prediction\",\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_name=f\"modelstock_pred_{str(datetime.now().date())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "        path=f\"azureml://jobs/{job.name}/outputs/artifacts/paths/outputs/\",\n",
    "        name=\"model-path\",\n",
    "        description=\"Model created from run.\",\n",
    "        type=\"custom_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.models.create_or_update(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create endpoint\n",
    "online_endpoint_name = \"modeldir-logged-init\"\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\"\n",
    ")\n",
    "\n",
    "ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create deployment only after endpoint has provisioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment script\n",
    "code_config = CodeConfiguration(\n",
    "        code=src_dir, scoring_script=\"deployment.py\"\n",
    "    )\n",
    "\n",
    "# Create deployment\n",
    "yellow_deployment = ManagedOnlineDeployment(\n",
    "    name=\"yellow\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=modeldir,\n",
    "    environment=Environment(\n",
    "            conda_file=f\"./{dependencies_dir}/conda.yml\",\n",
    "            image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\"),\n",
    "    code_configuration=code_config,\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "# create the deployment:\n",
    "ml_client.begin_create_or_update(yellow_deployment)\n",
    "# blue deployment takes 100 traffic\n",
    "# endpoint.traffic = {\"yellow\": 100}\n",
    "# ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inputs.json\n",
    "{\"d1\":2663,\"d2\":2654.4,\"d3\":2698,\"d4\":2690,\"d5\":2698.12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the endpoint (the request will route to blue deployment as set above)\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"yellow\",\n",
    "    request_file=\"inputs.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.compute.begin_delete(name=compute.name).wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployed endpoint logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"yellow\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = str(datetime.today().date()-timedelta(days=14))\n",
    "end = str(datetime.today().date()-timedelta(days=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(TICKER=\"LT.NS\"):\n",
    "\n",
    "    try:\n",
    "        start = str(datetime.today().date()-timedelta(days=366))\n",
    "        end = str(datetime.today().date()-timedelta(days=1))\n",
    "\n",
    "        tickerData=yf.download(TICKER,start=start, end=end, period='1d')\n",
    "        tickerData['Date']=[str(x)[:10] for x in tickerData.index]\n",
    "        tickerData['Ticker']=TICKER\n",
    "        tickerData = tickerData['Adj Close']\n",
    "    \n",
    "        if tickerData.shape[0]==0:\n",
    "            raise ValueError(\"No data found via YFinance.\")\n",
    "    except:\n",
    "        # logging.error(\"Problem with downloading data from YFinance.\")\n",
    "        tickerData=None\n",
    "    finally:\n",
    "        return tickerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerData=get_ticker_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('-','',str(datetime.today().date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tickerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags={'Length':len(tickerData),'Median':tickerData.median(),'SD':tickerData.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(tickerData.index[0].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(tickerData.index[-1].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv(\"../data/LT.NS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.index = td[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.drop([\"Date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.index[-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_client():\n",
    "\n",
    "    with open('../config/config.json','r') as f:\n",
    "        configs=json.loads(f.read())\n",
    "\n",
    "    subscription_id, resource_group, workspace = configs['subscription_id'], configs['resource_group'], configs['workspace_name']\n",
    "\n",
    "    try:\n",
    "        credential = DefaultAzureCredential()\n",
    "        # Check if given credential can get token successfully.\n",
    "        credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "        ml_client = MLClient(\n",
    "        credential, subscription_id, resource_group, workspace\n",
    "        )\n",
    "        return ml_client\n",
    "    except Exception as ex:\n",
    "\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc=get_ml_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../data/LT.NS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER=\"LT.NS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_data = pd.read_csv(path)\n",
    "ticker_data.index=ticker_data['Date']\n",
    "ticker_data.drop([\"Date\"],axis=1,inplace=True)\n",
    "data_to_upload=Data(\n",
    "        name=TICKER,\n",
    "        version=re.sub('-','',str(datetime.today().date())),\n",
    "        description=f\"Stock data for {TICKER} during {str(ticker_data.index[0][:10])}:{str(ticker_data.index[-1][:10])} in 1d interval.\",\n",
    "        type='uri_file',\n",
    "        ml_client=ml_client,\n",
    "        path=path,\n",
    "        tags={\n",
    "            'Length':len(ticker_data),\n",
    "            'Start':str(ticker_data.index[0][:10]),\n",
    "            'End':str(ticker_data.index[-1][:10]),\n",
    "            'Median':ticker_data.median(),\n",
    "            'SD':ticker_data.std()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "'LT.NS'[:'LT.NS'.index('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = str({\"filename\":'123',\"Date\":[1,2,3],\"Close\":[10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobs.data_download import get_ticker_data, get_dataset_tags, save_to_data_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd='LT.NS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd[:fd.index('.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updating training yamls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from copy import deepcopy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_pipeline.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.github/workflows/train_pipeline.yml','r') as f:\n",
    "    train_pipeline=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=re.findall('run-[0-9]',train_pipeline)\n",
    "run_id=run_id[0]\n",
    "run_n = int(re.findall('[0-9]',run_id)[0])\n",
    "new_run_id = f\"run-{run_n+1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run-1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id, new_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version=re.findall('--version [0-9]',train_pipeline)\n",
    "model_version = model_version[0]\n",
    "version = int(re.findall('[0-9]',model_version)[0])\n",
    "new_model_version = f\"--version {version+1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline= re.sub(model_version, new_model_version, train_pipeline)\n",
    "train_pipeline=re.sub(run_id, new_run_id, train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.github/workflows/train_pipeline.yml','w') as f:\n",
    "    f.write(train_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../jobs/train.yml','r') as f:\n",
    "    train=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_path=train[train.index('path:'):train.index('@latest')].split(\":\")\n",
    "with open('../.github/workflows/data_pipeline.yml','r') as f:\n",
    "    data_pipeline=f.read()\n",
    "ticker_string=data_pipeline[data_pipeline.index('ticker'): data_pipeline.index('.NS')]\n",
    "ticker=ticker_string[ticker_string.index(':'):].strip(\":\").strip(\" \")\n",
    "new_uri_path = deepcopy(uri_path)\n",
    "new_uri_path[2]=ticker\n",
    "uri_path=\":\".join(uri_path)\n",
    "new_uri_path=\":\".join(new_uri_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=re.sub(run_id, new_run_id, train)\n",
    "train=re.sub(uri_path, new_uri_path, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../jobs/train.yml','w') as f:\n",
    "    f.write(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495794734634ed83a223a0ff466dd16659bfe4b87c179f1ac740ad96b06e37ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
